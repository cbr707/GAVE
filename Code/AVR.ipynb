{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is example code for measuring Arterioveneous ratio (AVR). We followed the clinical experience of ophthalmologists and measured the vascular arteriovenous ratio at the optic disc margin. You can also implement the measurement process yourself, just follow the standards of the measurement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 \n",
    "First we need to get the segmentation result from the raw probability image of the model prediction."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T04:58:20.300504Z",
     "start_time": "2025-08-21T04:58:20.297649Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T04:58:20.764330Z",
     "start_time": "2025-08-21T04:58:20.758131Z"
    }
   },
   "source": [
    "def get_result(in_dir, out_dir, thresh=0.5):\n",
    "    '''\n",
    "        Obtain the partitioned graph from the probability graph, using only the R and B channels, and then place the intersection part in G\n",
    "    '''\n",
    "    \n",
    "    out_Path = Path(out_dir)\n",
    "    out_Path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for prob in Path(in_dir).glob(\"*.png\"):\n",
    "        out_filepath = out_Path / prob.name\n",
    "        \n",
    "        try:\n",
    "            with Image.open(prob) as img:\n",
    "                img_array = np.array(img)\n",
    "                \n",
    "            if img_array.dtype == np.uint8:\n",
    "                img_array = img_array.astype(np.float32) / 255.0\n",
    "            elif img_array.dtype == np.uint16:\n",
    "                img_array = img_array.astype(np.float32) / 65535.0\n",
    "                \n",
    "            r = img_array[:, :, 0]\n",
    "            g = img_array[:, :, 1]\n",
    "            b = img_array[:, :, 2]\n",
    "            \n",
    "            r_c = (r > thresh).astype(np.float32)\n",
    "            b_c = (b > thresh).astype(np.float32)\n",
    "            g_c = (r_c>0) & (b_c>0)\n",
    "            \n",
    "            seg = np.zeros_like(img_array)\n",
    "            \n",
    "            seg[:, :, 0] = r_c\n",
    "            seg[:, :, 2] = b_c\n",
    "            \n",
    "            seg[g_c, 0] = 0\n",
    "            seg[g_c, 1] = 1\n",
    "            seg[g_c, 2] = 0\n",
    "            \n",
    "            seg = (seg*255).astype(np.uint8)\n",
    "            Image.fromarray(seg).save(out_filepath)\n",
    "            \n",
    "            print(f\"Save to {out_filepath}\")            \n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Reading img {prob} error{e}\")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T05:08:40.947492Z",
     "start_time": "2025-08-21T05:08:38.151705Z"
    }
   },
   "source": [
    "# 目标文件夹用于存放过程文件以及最终测量结果\n",
    "target_folder = \"/data/disk8T2/caobr/202507GAVE/GAVE-main/Log/GAVE+seg_test20250817-111905_SMPUNetV3_lr1e-04_RRLossNew-BCETversky3Loss_bc16/pred/val2/\"\n",
    "# 概率图存放路径\n",
    "# in_dir = '/data/disk8T2/lincy/Lincy2025/GAVE-main/Log/GAVE_enhanced_train_GAVENetlcy_GAVENet_lr1e-04_RRLoss-BCE3Loss_bc16/pred/val_results_enhanced' # path of the model prediction, probability map\n",
    "in_dir = target_folder # path of the model prediction, probability map\n",
    "# 二值化分割图输出位置，不用修改\n",
    "out_dir = os.path.join(target_folder, \"seg\") # path to save the seg result \n",
    "thresh = 0.5            \n",
    "get_result(in_dir, out_dir, thresh)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to /data/disk8T2/caobr/202507GAVE/GAVE-main/Log/GAVE+seg_test20250817-111905_SMPUNetV3_lr1e-04_RRLossNew-BCETversky3Loss_bc16/pred/val2/seg/g_042.png\n",
      "Save to /data/disk8T2/caobr/202507GAVE/GAVE-main/Log/GAVE+seg_test20250817-111905_SMPUNetV3_lr1e-04_RRLossNew-BCETversky3Loss_bc16/pred/val2/seg/g_045.png\n",
      "Save to /data/disk8T2/caobr/202507GAVE/GAVE-main/Log/GAVE+seg_test20250817-111905_SMPUNetV3_lr1e-04_RRLossNew-BCETversky3Loss_bc16/pred/val2/seg/g_046.png\n",
      "Save to /data/disk8T2/caobr/202507GAVE/GAVE-main/Log/GAVE+seg_test20250817-111905_SMPUNetV3_lr1e-04_RRLossNew-BCETversky3Loss_bc16/pred/val2/seg/g_041.png\n",
      "Save to /data/disk8T2/caobr/202507GAVE/GAVE-main/Log/GAVE+seg_test20250817-111905_SMPUNetV3_lr1e-04_RRLossNew-BCETversky3Loss_bc16/pred/val2/seg/g_044.png\n",
      "Save to /data/disk8T2/caobr/202507GAVE/GAVE-main/Log/GAVE+seg_test20250817-111905_SMPUNetV3_lr1e-04_RRLossNew-BCETversky3Loss_bc16/pred/val2/seg/g_049.png\n",
      "Save to /data/disk8T2/caobr/202507GAVE/GAVE-main/Log/GAVE+seg_test20250817-111905_SMPUNetV3_lr1e-04_RRLossNew-BCETversky3Loss_bc16/pred/val2/seg/g_050.png\n",
      "Save to /data/disk8T2/caobr/202507GAVE/GAVE-main/Log/GAVE+seg_test20250817-111905_SMPUNetV3_lr1e-04_RRLossNew-BCETversky3Loss_bc16/pred/val2/seg/g_048.png\n",
      "Save to /data/disk8T2/caobr/202507GAVE/GAVE-main/Log/GAVE+seg_test20250817-111905_SMPUNetV3_lr1e-04_RRLossNew-BCETversky3Loss_bc16/pred/val2/seg/g_047.png\n",
      "Save to /data/disk8T2/caobr/202507GAVE/GAVE-main/Log/GAVE+seg_test20250817-111905_SMPUNetV3_lr1e-04_RRLossNew-BCETversky3Loss_bc16/pred/val2/seg/g_043.png\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2\n",
    "Get optic disc segmentation. We first get the optic disk segmentation result from MNet(https://github.com/HzFu/MNet_DeepCDR). \n",
    "\n",
    "You just need to config the virtual enviroment for running and then run the \"Step_3_MNet_test.py\" of MNet to get the optic disc result. We made some modified , you can refer our code, or just change the \"Step_3_MNet_test.py\" with our modified \"Step_3_MNet_test.py\". You can find it in our code file.\n",
    "\n",
    "After getting the optic disk segmentation results, we extract the contour of the result for next step."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T05:08:42.335434Z",
     "start_time": "2025-08-21T05:08:42.332962Z"
    }
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T05:08:42.875689Z",
     "start_time": "2025-08-21T05:08:42.867629Z"
    }
   },
   "source": [
    "\n",
    "def reconstruct_disc_circle(disc_mask):\n",
    "    \"\"\"\n",
    "        Input the segmented image and output the fitted circular mask image (of uint8 type, with values of 0 or 255)\n",
    "    \"\"\"\n",
    "    if disc_mask.max() <= 1:\n",
    "        disc_mask = (disc_mask * 255).astype(np.uint8)\n",
    "    else:\n",
    "        disc_mask = disc_mask.astype(np.uint8)\n",
    "\n",
    "    contours, _ = cv2.findContours(disc_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        raise ValueError(\"The outline was not found. Skip this picture\")\n",
    "\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Fit the minimum circumscribed circle\n",
    "    (x, y), radius = cv2.minEnclosingCircle(largest_contour)\n",
    "    center = (int(x), int(y))\n",
    "    radius = int(radius)\n",
    "\n",
    "    circle_mask = np.zeros_like(disc_mask, dtype=np.uint8)\n",
    "    cv2.circle(circle_mask, center, radius, 255, 1)\n",
    "\n",
    "    return circle_mask\n",
    "\n",
    "def process_all_images(in_dir, out_dir, suffixes=('.png', '.jpg', '.bmp')):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(in_dir) if f.lower().endswith(suffixes)]\n",
    "\n",
    "    for fname in tqdm(files, desc=\"Processing masks\"):\n",
    "        in_path = os.path.join(in_dir, fname)\n",
    "        out_path = os.path.join(out_dir, fname)\n",
    "\n",
    "        try:\n",
    "            mask = cv2.imread(in_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                print(f\"Can't read the file : {in_path}, jump it\")\n",
    "                continue\n",
    "            circle_mask = reconstruct_disc_circle(mask)\n",
    "            cv2.imwrite(out_path, circle_mask)\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] When processing {fname} encounter: {e}\")"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T05:08:47.463467Z",
     "start_time": "2025-08-21T05:08:43.484930Z"
    }
   },
   "source": [
    "# 待测数据的视盘分割结果，该路径下已经存放了测试集和训练集的全部视盘分割机结果，按需修改输入\n",
    "in_dir = '/data/disk8T2/caobr/202507GAVE/GAVE-main/Data/optic2/training'  # path of your optic disc segmentation result from MNet\n",
    "out_dir = os.path.join(target_folder, \"optic\")   # path to save optic disc contour\n",
    "process_all_images(in_dir, out_dir)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing masks: 100%|██████████| 50/50 [00:03<00:00, 12.66it/s]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3\n",
    "Then, we measure AVR"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T05:08:50.459368Z",
     "start_time": "2025-08-21T05:08:50.455807Z"
    }
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from collections import defaultdict\n",
    "import traceback\n",
    "import math"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T05:08:51.030038Z",
     "start_time": "2025-08-21T05:08:51.001712Z"
    }
   },
   "source": [
    "def process_image(av_img_path, disc_img_path):\n",
    "    try:\n",
    "        av_img = cv2.imread(av_img_path, cv2.IMREAD_COLOR)\n",
    "        disc_img = cv2.imread(disc_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if av_img is None:\n",
    "            print(f\"Error: Unable to read A/V images: {av_img_path}\")\n",
    "            return None, None, None, None\n",
    "        if disc_img is None:\n",
    "            print(f\"Error: Disc images cannot be read: {disc_img_path}\")\n",
    "            return None, None, None, None\n",
    "        \n",
    "        if av_img.shape[:2] != disc_img.shape:\n",
    "            disc_img = cv2.resize(disc_img, (av_img.shape[1], av_img.shape[0]))\n",
    "        \n",
    "        _, disc_mask = cv2.threshold(disc_img, 200, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        artery_img = np.zeros_like(av_img)\n",
    "        vein_img = np.zeros_like(av_img)\n",
    "\n",
    "        artery_mask = np.logical_or(\n",
    "            np.all(av_img == [0, 0, 255], axis=-1),  \n",
    "            np.all(av_img == [0, 255, 0], axis=-1)   \n",
    "        )\n",
    "        vein_mask = np.logical_or(\n",
    "            np.all(av_img == [255, 0, 0], axis=-1),  \n",
    "            np.all(av_img == [0, 255, 0], axis=-1)   \n",
    "        )\n",
    "        \n",
    "\n",
    "        artery_img[artery_mask] = [0, 0, 255] \n",
    "        vein_img[vein_mask] = [255, 0, 0] \n",
    "\n",
    "        final_artery_img = cv2.bitwise_and(artery_img, artery_img, mask=disc_mask)\n",
    "        final_vein_img = cv2.bitwise_and(vein_img, vein_img, mask=disc_mask)\n",
    "        \n",
    "        artery_gray = cv2.cvtColor(final_artery_img, cv2.COLOR_BGR2GRAY)\n",
    "        _, artery_bin = cv2.threshold(artery_gray, 1, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        num_labels_red, _, stats_red, _ = cv2.connectedComponentsWithStats(\n",
    "            artery_bin, 8, cv2.CV_32S\n",
    "        )\n",
    "        red_arcs = []\n",
    "        red_components = []\n",
    "        for i in range(1, num_labels_red):  \n",
    "            area = stats_red[i, cv2.CC_STAT_AREA]\n",
    "            red_arcs.append(int(area))\n",
    "            red_components.append(stats_red[i])\n",
    "        \n",
    "        vein_gray = cv2.cvtColor(final_vein_img, cv2.COLOR_BGR2GRAY)\n",
    "        _, vein_bin = cv2.threshold(vein_gray, 1, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        num_labels_blue, _, stats_blue, _ = cv2.connectedComponentsWithStats(\n",
    "            vein_bin, 8, cv2.CV_32S\n",
    "        )\n",
    "        blue_arcs = []\n",
    "        blue_components = []\n",
    "        for i in range(1, num_labels_blue):  \n",
    "            area = stats_blue[i, cv2.CC_STAT_AREA]\n",
    "            blue_arcs.append(int(area))\n",
    "            blue_components.append(stats_blue[i])\n",
    "        \n",
    "        red_arcs_sorted = sorted(red_arcs, reverse=True)[:4]\n",
    "        blue_arcs_sorted = sorted(blue_arcs, reverse=True)[:4]\n",
    "        \n",
    "        red_top4_avg = np.mean(red_arcs_sorted) if red_arcs_sorted else 0\n",
    "        blue_top4_avg = np.mean(blue_arcs_sorted) if blue_arcs_sorted else 0\n",
    "        \n",
    "        ratio = red_top4_avg / blue_top4_avg if blue_top4_avg > 0 else float('inf')\n",
    "        \n",
    "        visualization_a = np.zeros_like(av_img)\n",
    "        visualization_v = np.zeros_like(av_img)\n",
    "        \n",
    "        visualization_a[np.where(final_artery_img[:, :, 2] > 0)] = [0, 0, 255]\n",
    "        visualization_v[np.where(final_vein_img[:, :, 0] > 0)] = [255, 0, 0]\n",
    "        \n",
    "        for stat in red_components:\n",
    "            x, y, w, h, area = stat\n",
    "            cv2.rectangle(visualization_a, (x-5, y-5), (x + w + 5, y + h + 5), (0, 255, 255), 1)\n",
    "            cv2.putText(visualization_a, f\"A:{int(area)}\", (x, y - 5), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "        \n",
    "        for stat in blue_components:\n",
    "            x, y, w, h, area = stat\n",
    "            cv2.rectangle(visualization_v, (x-5, y-5), (x + w + 5, y + h + 5), (255, 255, 0), 1)\n",
    "            cv2.putText(visualization_v, f\"V:{int(area)}\", (x, y - 5), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)\n",
    "        \n",
    "        cv2.putText(visualization_a, f\"Red Top4: {red_top4_avg:.1f} ({ratio:.2f})\", \n",
    "                   (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "        cv2.putText(visualization_v, f\"Blue Top4: {blue_top4_avg:.1f}\", \n",
    "                   (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)\n",
    "        \n",
    "        disc_colored = cv2.cvtColor(disc_mask, cv2.COLOR_GRAY2BGR)\n",
    "        av_img_resized = cv2.resize(av_img, (disc_colored.shape[1], disc_colored.shape[0]))\n",
    "        top_row = np.hstack((av_img_resized, disc_colored))\n",
    "        bottom_row = np.hstack((visualization_a, visualization_v))\n",
    "        comparison = np.vstack((top_row, bottom_row))\n",
    "        \n",
    "        return red_arcs, blue_arcs, comparison, os.path.basename(av_img_path), red_top4_avg, blue_top4_avg, ratio\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred when processing the picture: {av_img_path}\")\n",
    "        print(traceback.format_exc())\n",
    "        return None, None, None, None, None, None, None\n",
    "\n",
    "def process_images(av_dir, disc_dir, comparison_dir=None, log_file=None):\n",
    "    supported_formats = (\".png\")\n",
    "    av_files = [f for f in os.listdir(av_dir) if f.lower().endswith(supported_formats)]\n",
    "\n",
    "    if comparison_dir and not os.path.exists(comparison_dir):\n",
    "        os.makedirs(comparison_dir)\n",
    "    \n",
    "    all_results = []\n",
    "    logs = []  \n",
    "    ratios = [] \n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for filename in av_files:\n",
    "            av_path = os.path.join(av_dir, filename)\n",
    "            disc_path = os.path.join(disc_dir, filename)\n",
    "            \n",
    "            if os.path.exists(disc_path):\n",
    "                futures.append(executor.submit(process_image, av_path, disc_path))\n",
    "            else:\n",
    "                log = f\"Warning: {filename}  does not exist in the Disc directory\"\n",
    "                print(log)\n",
    "                logs.append(log)\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result is None:\n",
    "                continue\n",
    "                \n",
    "            red_arcs, blue_arcs, comparison_img, filename, red_top4_avg, blue_top4_avg, ratio = result\n",
    "            \n",
    "            if red_arcs is not None and comparison_img is not None:\n",
    "                if comparison_dir:\n",
    "                    comp_path = os.path.join(comparison_dir, f\"comparison_{filename}\")\n",
    "                    cv2.imwrite(comp_path, comparison_img)\n",
    "                \n",
    "                red_count = len(red_arcs)\n",
    "                blue_count = len(blue_arcs)\n",
    "                red_avg = sum(red_arcs) / red_count if red_count > 0 else 0\n",
    "                blue_avg = sum(blue_arcs) / blue_count if blue_count > 0 else 0\n",
    "                \n",
    "                all_results.append({\n",
    "                    \"filename\": filename,\n",
    "                    \"red_arcs\": red_arcs,\n",
    "                    \"blue_arcs\": blue_arcs,\n",
    "                    \"red_arc_count\": red_count,\n",
    "                    \"blue_arc_count\": blue_count,\n",
    "                    \"avg_red_arc\": red_avg,\n",
    "                    \"avg_blue_arc\": blue_avg,\n",
    "                    \"red_top4_avg\": red_top4_avg,\n",
    "                    \"blue_top4_avg\": blue_top4_avg,\n",
    "                    \"ratio\": ratio\n",
    "                })\n",
    "                \n",
    "                if math.isfinite(ratio) and ratio > 0:\n",
    "                    ratios.append(ratio)\n",
    "                \n",
    "                log = [\n",
    "                    f\"\\nProcessing completed: {filename}\",\n",
    "                    f\"Arterial arc: {red_count} segment, length: {red_arcs}\",\n",
    "                    f\"Average of the Top4 arteries: {red_top4_avg:.1f} pixles\",\n",
    "                    f\"Venous arc: {blue_count} segment, length: {blue_arcs}\",\n",
    "                    f\"Average of the Top4 veins: {blue_top4_avg:.1f} pixels\",\n",
    "                    f\"AVR: {ratio:.4f}\"\n",
    "                ]\n",
    "                \n",
    "                for line in log:\n",
    "                    print(line)\n",
    "                logs.extend(log)\n",
    "    \n",
    "    return all_results, logs, ratios\n",
    "\n",
    "def generate_report(results, ratios, report_path):\n",
    "    all_red_arcs = [arc for res in results for arc in res[\"red_arcs\"]]\n",
    "    all_blue_arcs = [arc for res in results for arc in res[\"blue_arcs\"]]\n",
    "    \n",
    "    ratio_avg = np.mean(ratios) if ratios else 0\n",
    "    ratio_std = np.std(ratios) if ratios else 0\n",
    "    \n",
    "    report = \"\\n\" + \"=\" * 60 + \"\\n\"\n",
    "    report += \"Summary (Based on Top-4 Average Length)\\n\"\n",
    "    report += \"=\" * 60 + \"\\n\"\n",
    "    report += \"Filename\".ljust(10) + \"AVR\\n\"\n",
    "    report += \"-\" * 60 + \"\\n\"\n",
    "    \n",
    "    for res in results:\n",
    "        filename = res[\"filename\"]\n",
    "        red_top4 = res[\"red_top4_avg\"]\n",
    "        blue_top4 = res[\"blue_top4_avg\"]\n",
    "        ratio = res[\"ratio\"]\n",
    "        \n",
    "        if math.isfinite(ratio):\n",
    "            report += f\"{filename.ljust(10)}\"\n",
    "            report += f\"{ratio:.4f}\\n\"\n",
    "        else:\n",
    "            report += f\"{filename.ljust(65)}{red_top4:.1f}\".ljust(15)\n",
    "            report += f\"{blue_top4:.1f}\".ljust(15)\n",
    "            report += \"N/A (no venous arcs)\\n\"\n",
    "    \n",
    "    report += \"\\nOverall ratio statistics:\\n\"\n",
    "    report += f\"Average AVR: {ratio_avg:.4f}\\n\"\n",
    "    report += f\"Standard deviation of AVR: {ratio_std:.4f}\\n\"\n",
    "    report += \"=\" * 60\n",
    "    \n",
    "    with open(report_path, 'a', encoding='utf-8') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    print(report)\n",
    "    \n",
    "    return report\n",
    "\n",
    "\n",
    "def AVR(av_dir, disc_dir, comparison_dir, report_path):\n",
    "    \n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\" * 60 + \"\\n\")\n",
    "        f.write(\"AVR Analysis Report (Based on Top-4 Average Length)\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    \n",
    "    results, logs, ratios = process_images(av_dir, disc_dir, comparison_dir, report_path)\n",
    "\n",
    "    with open(report_path, 'a', encoding='utf-8') as f:\n",
    "        for log in logs:\n",
    "            f.write(log + \"\\n\")\n",
    "\n",
    "    if results:\n",
    "        generate_report(results, ratios, report_path)\n",
    "\n",
    "        all_red_top4 = [res[\"red_top4_avg\"] for res in results]\n",
    "        all_blue_top4 = [res[\"blue_top4_avg\"] for res in results]\n",
    "\n",
    "        print(\"\\nFinal Summary:\")\n",
    "        print(f\"Overall average of artery Top-4: {np.mean(all_red_top4):.1f}\")\n",
    "        print(f\"Overall average of vein Top-4: {np.mean(all_blue_top4):.1f}\")\n",
    "        print(f\"Overall AVR: {np.mean(ratios):.4f}\")\n",
    "        \n",
    "        # Write final summary to file\n",
    "        with open(report_path, 'a', encoding='utf-8') as f:\n",
    "            f.write(\"\\n\\nFinal Summary:\\n\")\n",
    "            f.write(f\"Overall average of artery (red) Top-4: {np.mean(all_red_top4):.1f}\\n\")\n",
    "            f.write(f\"Overall average of vein Top-4: {np.mean(all_blue_top4):.1f}\\n\")\n",
    "            f.write(f\"Overall AVR: {np.mean(ratios):.4f}\\n\")\n",
    "    else:\n",
    "        print(\"No valid images found for processing.\")\n",
    "        with open(report_path, 'a', encoding='utf-8') as f:\n",
    "            f.write(\"\\nNo valid images found for processing.\\n\")\n",
    "    \n",
    "    print(f\"Report saved to: {report_path}\")\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T05:08:54.396523Z",
     "start_time": "2025-08-21T05:08:51.789241Z"
    }
   },
   "source": [
    "av_dir = os.path.join(target_folder, \"seg\")       # the binary A/V seg result filedirectory\n",
    "disc_dir = os.path.join(target_folder, \"optic\")   # path of optic disc contour \n",
    "comparison_dir = os.path.join(target_folder, \"visual\")  # path to save the visualization result\n",
    "report_path = os.path.join(target_folder, \"AVR/AVR.txt\")   # path of AVR value\n",
    "if not os.path.exists(os.path.join(target_folder, \"AVR\")):\n",
    "    os.mkdir(os.path.join(target_folder, \"AVR\"))\n",
    "\n",
    "\n",
    "AVR(av_dir, disc_dir, comparison_dir, report_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing completed: g_042.png\n",
      "Arterial arc: 8 segment, length: [9, 4, 5, 3, 2, 4, 7, 13]\n",
      "Average of the Top4 arteries: 8.5 pixles\n",
      "Venous arc: 10 segment, length: [10, 8, 5, 4, 5, 2, 7, 1, 1, 13]\n",
      "Average of the Top4 veins: 9.5 pixels\n",
      "AVR: 0.8947\n",
      "\n",
      "Processing completed: g_045.png\n",
      "Arterial arc: 9 segment, length: [6, 5, 4, 3, 5, 2, 4, 9, 3]\n",
      "Average of the Top4 arteries: 6.2 pixles\n",
      "Venous arc: 6 segment, length: [30, 11, 6, 9, 5, 9]\n",
      "Average of the Top4 veins: 14.8 pixels\n",
      "AVR: 0.4237\n",
      "\n",
      "Processing completed: g_049.png\n",
      "Arterial arc: 8 segment, length: [8, 5, 5, 3, 4, 6, 3, 4]\n",
      "Average of the Top4 arteries: 6.0 pixles\n",
      "Venous arc: 6 segment, length: [12, 6, 6, 6, 10, 10]\n",
      "Average of the Top4 veins: 9.5 pixels\n",
      "AVR: 0.6316\n",
      "\n",
      "Processing completed: g_048.png\n",
      "Arterial arc: 6 segment, length: [9, 4, 6, 8, 4, 10]\n",
      "Average of the Top4 arteries: 8.2 pixles\n",
      "Venous arc: 8 segment, length: [4, 2, 8, 5, 10, 7, 8, 13]\n",
      "Average of the Top4 veins: 9.8 pixels\n",
      "AVR: 0.8462\n",
      "\n",
      "Processing completed: g_043.png\n",
      "Arterial arc: 7 segment, length: [3, 3, 4, 6, 4, 4, 7]\n",
      "Average of the Top4 arteries: 5.2 pixles\n",
      "Venous arc: 9 segment, length: [12, 12, 8, 8, 5, 9, 7, 19, 9]\n",
      "Average of the Top4 veins: 13.0 pixels\n",
      "AVR: 0.4038\n",
      "\n",
      "Processing completed: g_046.png\n",
      "Arterial arc: 9 segment, length: [6, 7, 3, 3, 5, 4, 3, 3, 5]\n",
      "Average of the Top4 arteries: 5.8 pixles\n",
      "Venous arc: 7 segment, length: [10, 9, 9, 6, 1, 13, 1]\n",
      "Average of the Top4 veins: 10.2 pixels\n",
      "AVR: 0.5610\n",
      "\n",
      "Processing completed: g_044.png\n",
      "Arterial arc: 6 segment, length: [7, 2, 5, 6, 5, 6]\n",
      "Average of the Top4 arteries: 6.0 pixles\n",
      "Venous arc: 4 segment, length: [12, 10, 25, 1]\n",
      "Average of the Top4 veins: 12.0 pixels\n",
      "AVR: 0.5000\n",
      "\n",
      "Processing completed: g_047.png\n",
      "Arterial arc: 8 segment, length: [6, 5, 3, 6, 5, 3, 2, 4]\n",
      "Average of the Top4 arteries: 5.5 pixles\n",
      "Venous arc: 7 segment, length: [15, 3, 5, 5, 6, 13, 11]\n",
      "Average of the Top4 veins: 11.2 pixels\n",
      "AVR: 0.4889\n",
      "\n",
      "Processing completed: g_050.png\n",
      "Arterial arc: 9 segment, length: [7, 4, 3, 4, 4, 4, 3, 4, 7]\n",
      "Average of the Top4 arteries: 5.5 pixles\n",
      "Venous arc: 7 segment, length: [11, 7, 3, 3, 14, 8, 11]\n",
      "Average of the Top4 veins: 11.0 pixels\n",
      "AVR: 0.5000\n",
      "\n",
      "Processing completed: g_041.png\n",
      "Arterial arc: 6 segment, length: [5, 4, 3, 4, 5, 5]\n",
      "Average of the Top4 arteries: 4.8 pixles\n",
      "Venous arc: 4 segment, length: [11, 6, 1, 11]\n",
      "Average of the Top4 veins: 7.2 pixels\n",
      "AVR: 0.6552\n",
      "\n",
      "============================================================\n",
      "Summary (Based on Top-4 Average Length)\n",
      "============================================================\n",
      "Filename  AVR\n",
      "------------------------------------------------------------\n",
      "g_042.png 0.8947\n",
      "g_045.png 0.4237\n",
      "g_049.png 0.6316\n",
      "g_048.png 0.8462\n",
      "g_043.png 0.4038\n",
      "g_046.png 0.5610\n",
      "g_044.png 0.5000\n",
      "g_047.png 0.4889\n",
      "g_050.png 0.5000\n",
      "g_041.png 0.6552\n",
      "\n",
      "Overall ratio statistics:\n",
      "Average AVR: 0.5905\n",
      "Standard deviation of AVR: 0.1594\n",
      "============================================================\n",
      "\n",
      "Final Summary:\n",
      "Overall average of artery Top-4: 6.2\n",
      "Overall average of vein Top-4: 10.8\n",
      "Overall AVR: 0.5905\n",
      "Report saved to: /data/disk8T2/caobr/202507GAVE/GAVE-main/Log/GAVE+seg_test20250817-111905_SMPUNetV3_lr1e-04_RRLossNew-BCETversky3Loss_bc16/pred/val2/AVR/AVR.txt\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4\n",
    "\n",
    "Evaluation the AVR result"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T05:08:57.083874Z",
     "start_time": "2025-08-21T05:08:57.076380Z"
    }
   },
   "source": [
    "def load_values(file_path):\n",
    "    \"\"\"\n",
    "    retrun dict: {filename: value}\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip() == '':\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            fname, value = parts\n",
    "            try:\n",
    "                data[fname] = float(value)\n",
    "            except ValueError:\n",
    "                print(f\"[Warning] Skip invalid lines: {line.strip()}\")\n",
    "    return data\n",
    "\n",
    "def eval_AVR(gt_dict, pred_dict):\n",
    "    common_keys = set(gt_dict.keys()) & set(pred_dict.keys())\n",
    "    if len(common_keys) == 0:\n",
    "        raise ValueError(\"There are no common file names available for comparison!\")\n",
    "\n",
    "    abs_errors = []\n",
    "    smape_values = []\n",
    "    print(\"Img_ID, GT, Pred\")\n",
    "    for k in common_keys:\n",
    "        \n",
    "        y_true = gt_dict[k]\n",
    "        y_pred = pred_dict[k]\n",
    "        print(k, y_true, y_pred)\n",
    "        \n",
    "        abs_errors.append(abs(y_true - y_pred))\n",
    "        denominator = (abs(y_true) + abs(y_pred)) / 2\n",
    "        if denominator == 0:\n",
    "            smape_values.append(0.0)\n",
    "        else:\n",
    "            smape_values.append(abs(y_true - y_pred) / denominator)\n",
    "\n",
    "    mae = sum(abs_errors) / len(abs_errors)\n",
    "    smape = 100 * sum(smape_values) / len(smape_values)\n",
    "\n",
    "    return mae, smape"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T05:09:02.066848Z",
     "start_time": "2025-08-21T05:09:02.061987Z"
    }
   },
   "source": [
    "gt_file = \"../Data/GAVE/training\"+\"/AVR.txt\"  # path of AVR groundtruth file\n",
    "pred_file = os.path.join(target_folder, \"AVR/AVR.txt\") # path of your AVR prediction file\n",
    "\n",
    "gt_values = load_values(gt_file)\n",
    "pred_values = load_values(pred_file)\n",
    "\n",
    "mae, smape = eval_AVR(gt_values, pred_values)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"SMAPE: {smape:.2f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Skip invalid lines: Filename  AVR\n",
      "[Warning] Skip invalid lines: Final Summary:\n",
      "Img_ID, GT, Pred\n",
      "g_047.png 0.9762 0.4889\n",
      "g_041.png 0.9828 0.6552\n",
      "g_049.png 0.4808 0.6316\n",
      "g_043.png 0.3934 0.4038\n",
      "g_050.png 0.9 0.5\n",
      "g_044.png 0.902 0.5\n",
      "g_042.png 1.375 0.8947\n",
      "g_045.png 0.5082 0.4237\n",
      "g_046.png 0.6429 0.561\n",
      "g_048.png 0.5333 0.8462\n",
      "MAE: 0.2738\n",
      "SMAPE: 37.02%\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
